{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import operator\n",
    "\n",
    "question = np.load('pad_question.npy')\n",
    "answer = np.load('pad_answer.npy')\n",
    "answer_o = np.load('answer_o.npy',allow_pickle=True)\n",
    "with open('vocab_bag.pkl', 'rb') as f:\n",
    "    words = pickle.load(f)\n",
    "with open('pad_word_to_index.pkl', 'rb') as f:\n",
    "    word_to_index = pickle.load(f)\n",
    "with open('pad_index_to_word.pkl', 'rb') as f:\n",
    "    index_to_word = pickle.load(f)\n",
    "vocab_size = len(word_to_index) + 1\n",
    "maxLen=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "def generate_train(batch_size):\n",
    "    print('\\n*********************************generate_train()*********************************')\n",
    "    steps=0\n",
    "    question_ = question\n",
    "    answer_ = answer\n",
    "    while True:\n",
    "        batch_answer_o = answer_o[steps:steps+batch_size]\n",
    "        batch_question = question_[steps:steps+batch_size]\n",
    "        batch_answer = answer_[steps:steps+batch_size]\n",
    "        outs = np.zeros([batch_size, maxLen, vocab_size], dtype='float32')\n",
    "        for pos, i in enumerate(batch_answer_o):\n",
    "            for pos_, j in enumerate(i):\n",
    "                if pos_ > 20:\n",
    "                    print(i)\n",
    "                outs[pos, pos_, j] = 1 # one-hot\n",
    "        yield [batch_question, batch_answer], outs\n",
    "        steps += batch_size\n",
    "        if steps == 100000:\n",
    "            steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers import Input, Dense, LSTM, TimeDistributed, Bidirectional, Dropout, Concatenate, RepeatVector, Activation, Dot\n",
    "from keras.layers import concatenate, dot                    \n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.initializers import TruncatedNormal\n",
    "import pydot\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 512 and 1024. Shapes are [512,256] and [1024,256]. for 'Assign_7' (op: 'Assign') with input shapes: [512,256], [1024,256].",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_create_c_op\u001B[1;34m(graph, node_def, inputs, control_inputs)\u001B[0m\n\u001B[0;32m   1606\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1607\u001B[1;33m     \u001B[0mc_op\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mc_api\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTF_FinishOperation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mop_desc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1608\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mInvalidArgumentError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Dimension 0 in both shapes must be equal, but are 512 and 1024. Shapes are [512,256] and [1024,256]. for 'Assign_7' (op: 'Assign') with input shapes: [512,256], [1024,256].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-4ef8fb409057>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'rmsprop'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'categorical_crossentropy'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 49\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_weights\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'models/W--184-0.5949-.h5'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     50\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\keras\\engine\\saving.py\u001B[0m in \u001B[0;36mload_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    456\u001B[0m                 \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mremove\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtmp_filepath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    457\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mres\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 458\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mload_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    459\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    460\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mload_wrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\keras\\engine\\network.py\u001B[0m in \u001B[0;36mload_weights\u001B[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001B[0m\n\u001B[0;32m   1215\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1216\u001B[0m                 saving.load_weights_from_hdf5_group(\n\u001B[1;32m-> 1217\u001B[1;33m                     f, self.layers, reshape=reshape)\n\u001B[0m\u001B[0;32m   1218\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'close'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1219\u001B[0m                 \u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\keras\\engine\\saving.py\u001B[0m in \u001B[0;36mload_weights_from_hdf5_group\u001B[1;34m(f, layers, reshape)\u001B[0m\n\u001B[0;32m   1197\u001B[0m                              ' elements.')\n\u001B[0;32m   1198\u001B[0m         \u001B[0mweight_value_tuples\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msymbolic_weights\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight_values\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1199\u001B[1;33m     \u001B[0mK\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch_set_value\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweight_value_tuples\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1200\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1201\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001B[0m in \u001B[0;36mbatch_set_value\u001B[1;34m(tuples)\u001B[0m\n\u001B[0;32m   2725\u001B[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001B[0;32m   2726\u001B[0m                                                     shape=value.shape)\n\u001B[1;32m-> 2727\u001B[1;33m                 \u001B[0massign_op\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0massign\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0massign_placeholder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2728\u001B[0m                 \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_assign_placeholder\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0massign_placeholder\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2729\u001B[0m                 \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_assign_op\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0massign_op\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001B[0m in \u001B[0;36massign\u001B[1;34m(self, value, use_locking, name, read_value)\u001B[0m\n\u001B[0;32m   2065\u001B[0m     \"\"\"\n\u001B[0;32m   2066\u001B[0m     assign = state_ops.assign(\n\u001B[1;32m-> 2067\u001B[1;33m         self._variable, value, use_locking=use_locking, name=name)\n\u001B[0m\u001B[0;32m   2068\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mread_value\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2069\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0massign\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\state_ops.py\u001B[0m in \u001B[0;36massign\u001B[1;34m(ref, value, validate_shape, use_locking, name)\u001B[0m\n\u001B[0;32m    225\u001B[0m     return gen_state_ops.assign(\n\u001B[0;32m    226\u001B[0m         \u001B[0mref\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0muse_locking\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muse_locking\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 227\u001B[1;33m         validate_shape=validate_shape)\n\u001B[0m\u001B[0;32m    228\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[0mref\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0massign\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    229\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_state_ops.py\u001B[0m in \u001B[0;36massign\u001B[1;34m(ref, value, validate_shape, use_locking, name)\u001B[0m\n\u001B[0;32m     64\u001B[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001B[0;32m     65\u001B[0m         \u001B[1;34m\"Assign\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mref\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mref\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidate_shape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mvalidate_shape\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 66\u001B[1;33m                   use_locking=use_locking, name=name)\n\u001B[0m\u001B[0;32m     67\u001B[0m   \u001B[0m_result\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_op\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m   \u001B[0m_inputs_flat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_op\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001B[0m in \u001B[0;36m_apply_op_helper\u001B[1;34m(self, op_type_name, name, **keywords)\u001B[0m\n\u001B[0;32m    792\u001B[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001B[0;32m    793\u001B[0m                          \u001B[0minput_types\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput_types\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattrs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattr_protos\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 794\u001B[1;33m                          op_def=op_def)\n\u001B[0m\u001B[0;32m    795\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    796\u001B[0m       \u001B[1;31m# Conditionally invoke tfdbg v2's op callback(s).\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001B[0m in \u001B[0;36mnew_func\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    505\u001B[0m                 \u001B[1;34m'in a future version'\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mdate\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;34m'after %s'\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mdate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    506\u001B[0m                 instructions)\n\u001B[1;32m--> 507\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    508\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    509\u001B[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001B[0m in \u001B[0;36mcreate_op\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m   3355\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Input #%d is not a tensor: %s\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3356\u001B[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001B[1;32m-> 3357\u001B[1;33m                                     attrs, op_def, compute_device)\n\u001B[0m\u001B[0;32m   3358\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3359\u001B[0m   def _create_op_internal(\n",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_create_op_internal\u001B[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001B[0m\n\u001B[0;32m   3424\u001B[0m           \u001B[0minput_types\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput_types\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3425\u001B[0m           \u001B[0moriginal_op\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_default_original_op\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3426\u001B[1;33m           op_def=op_def)\n\u001B[0m\u001B[0;32m   3427\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_create_op_helper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mret\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompute_device\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcompute_device\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3428\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mret\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001B[0m\n\u001B[0;32m   1768\u001B[0m           op_def, inputs, node_def.attr)\n\u001B[0;32m   1769\u001B[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001B[1;32m-> 1770\u001B[1;33m                                 control_input_ops)\n\u001B[0m\u001B[0;32m   1771\u001B[0m     \u001B[1;31m# pylint: enable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1772\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\tools\\python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_create_c_op\u001B[1;34m(graph, node_def, inputs, control_inputs)\u001B[0m\n\u001B[0;32m   1608\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mInvalidArgumentError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1609\u001B[0m     \u001B[1;31m# Convert to ValueError for backwards compatibility.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1610\u001B[1;33m     \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1611\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1612\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[0mc_op\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Dimension 0 in both shapes must be equal, but are 512 and 1024. Shapes are [512,256] and [1024,256]. for 'Assign_7' (op: 'Assign') with input shapes: [512,256], [1024,256]."
     ]
    }
   ],
   "source": [
    "truncatednormal = TruncatedNormal(mean=0.0, stddev=0.05)\n",
    "embed_layer = Embedding(input_dim=vocab_size, \n",
    "                        output_dim=100, \n",
    "                        mask_zero=True,\n",
    "                        input_length=None,\n",
    "                        embeddings_initializer= truncatednormal)\n",
    "LSTM_encoder = LSTM(512,\n",
    "                      return_sequences=True,\n",
    "                      return_state=True,\n",
    "                      kernel_initializer= 'lecun_uniform',\n",
    "                      name='encoder_lstm'\n",
    "                        )\n",
    "LSTM_decoder = LSTM(512, \n",
    "                    return_sequences=True, \n",
    "                    return_state=True, \n",
    "                    kernel_initializer= 'lecun_uniform',\n",
    "                    name='decoder_lstm'\n",
    "                   )\n",
    "\n",
    "#encoder输入 与 decoder输入\n",
    "input_question = Input(shape=(None, ), dtype='int32', name='input_question')\n",
    "input_answer = Input(shape=(None, ), dtype='int32', name='input_answer')\n",
    "\n",
    "input_question_embed = embed_layer(input_question)\n",
    "input_answer_embed = embed_layer(input_answer)\n",
    "\n",
    "\n",
    "encoder_lstm, question_h, question_c = LSTM_encoder(input_question_embed)\n",
    "\n",
    "decoder_lstm, _, _ = LSTM_decoder(input_answer_embed, \n",
    "                                  initial_state=[question_h, question_c])\n",
    "\n",
    "# attention = dot([decoder_lstm, encoder_lstm], axes=[2, 2])\n",
    "# attention = Activation('softmax')(attention)\n",
    "# context = dot([attention, encoder_lstm], axes=[2,1])\n",
    "# decoder_combined_context = concatenate([context, decoder_lstm])\n",
    "decoder_combined_context = decoder_lstm\n",
    "\n",
    "# Has another weight + tanh layer as described in equation (5) of the paper\n",
    "decoder_dense1 = TimeDistributed(Dense(256,activation=\"tanh\"))\n",
    "decoder_dense2 = TimeDistributed(Dense(vocab_size,activation=\"softmax\"))\n",
    "output = decoder_dense1(decoder_combined_context) # equation (5) of the paper\n",
    "output = decoder_dense2(output) # equation (6) of the paper\n",
    "\n",
    "model = Model([input_question, input_answer], output)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "model.load_weights('models/W--184-0.5949-.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_model = Model(input_question, [encoder_lstm, question_h, question_c])\n",
    "question_model.summary()\n",
    "answer_h = Input(shape=(512,))\n",
    "answer_c = Input(shape=(512,))\n",
    "encoder_lstm = Input(shape=(maxLen,512))\n",
    "target, h, c = LSTM_decoder(input_answer_embed, initial_state=[answer_h, answer_c])\n",
    "# attention = dot([target, encoder_lstm], axes=[2, 2])\n",
    "# attention_ = Activation('softmax')(attention)\n",
    "# context = dot([attention_, encoder_lstm], axes=[2,1])\n",
    "# decoder_combined_context = concatenate([context, target])\n",
    "decoder_combined_context = target\n",
    "output = decoder_dense1(decoder_combined_context) # equation (5) of the paper\n",
    "output = decoder_dense2(output) # equation (6) of the paper\n",
    "answer_model = Model([input_answer, answer_h, answer_c, encoder_lstm], [output, h, c])\n",
    "answer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import jieba\n",
    "import requests\n",
    "def act_weather(city):\n",
    "    #TODO: Get weather by api\n",
    "    url = 'http://wthrcdn.etouch.cn/weather_mini?city=' + city\n",
    "    page = requests.get(url)\n",
    "    data = page.json()\n",
    "    temperature = data['data']['wendu']\n",
    "    notice = data['data']['ganmao']\n",
    "    outstrs = \"地点： %s\\n气温： %s\\n注意： %s\" % (city, temperature, notice)\n",
    "    return outstrs + ' EOS'\n",
    "def input_question(seq):\n",
    "    seq = jieba.lcut(seq.strip(), cut_all=False)\n",
    "    sentence = seq\n",
    "    try:\n",
    "        seq = np.array([word_to_index[w] for w in seq])\n",
    "    except KeyError:\n",
    "        seq = np.array([36874, 165, 14625])\n",
    "    seq = sequence.pad_sequences([seq], maxlen=maxLen,\n",
    "                                          padding='post', truncating='post')\n",
    "    print(seq)\n",
    "    return seq, sentence\n",
    "def decode_greedy(seq, sentence):\n",
    "    question = seq\n",
    "    for index in question[0]:\n",
    "        if int(index) == 5900:\n",
    "            for index_ in question[0]:\n",
    "                if index_ in [7851, 11842,2406, 3485, 823, 12773, 8078]:\n",
    "                    return act_weather(index_to_word[index_])\n",
    "    answer = np.zeros((1, 1))\n",
    "#     attention_plot = np.zeros((20, 20))\n",
    "    answer[0, 0] = word_to_index['BOS']\n",
    "    i=1\n",
    "    answer_ = []\n",
    "    flag = 0\n",
    "    encoder_lstm_, question_h, question_c = question_model.predict(x=question, verbose=1)\n",
    "#     print(question_h, '\\n')\n",
    "    while flag != 1:\n",
    "        prediction, prediction_h, prediction_c = answer_model.predict([\n",
    "            answer, question_h, question_c, encoder_lstm_\n",
    "        ])\n",
    "#         attention_weights = attention.reshape(-1, )\n",
    "#         attention_plot[i] = attention_weights\n",
    "        word_arg = np.argmax(prediction[0, -1, :])#\n",
    "        answer_.append(index_to_word[word_arg])\n",
    "        if word_arg == word_to_index['EOS']  or i > 20:\n",
    "            flag = 1\n",
    "        answer = np.zeros((1, 1))\n",
    "        answer[0, 0] = word_arg\n",
    "        question_h = prediction_h\n",
    "        question_c = prediction_c\n",
    "        i += 1\n",
    "    result = ' '.join(answer_)\n",
    "#     attention_plot = attention_plot[:len(result.split(' ')), :len(sentence)]\n",
    "#     plot_attention(attention_plot, sentence, result.split(' '))\n",
    "    return ' '.join(answer_)\n",
    "def decode_beamsearch(seq, beam_size):\n",
    "    question = seq\n",
    "    encoder_lstm_, question_h, question_c = question_model.predict(x=question, verbose=1)\n",
    "    sequences = [[[word_to_index['BOS']], 1.0, question_h, question_c]]\n",
    "    answer = np.zeros((1, 1))\n",
    "    answer[0, 0] = word_to_index['BOS']\n",
    "    answer_ = ''\n",
    "    flag = 0\n",
    "    last_words = [word_to_index['BOS']]\n",
    "    for i in range(maxLen):\n",
    "        all_candidates = []\n",
    "        for j in range(len(sequences)):\n",
    "            s, score, h, c = sequences[j]\n",
    "            last_word = s[-1]\n",
    "            if not isinstance(last_word, int):\n",
    "                last_word=last_word[-1]\n",
    "            answer[0, 0] = last_word\n",
    "            output, h, c, _ = answer_model.predict([answer, h, c, encoder_lstm_])\n",
    "            output = output[0, -1]\n",
    "            for k in range(len(output)):\n",
    "                candidate = [seq+[k], score*-np.log(output[k]), h, c]\n",
    "            all_candidates.append(candidate)\n",
    "        ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "        sequences = ordered[:beam_size]\n",
    "    answer_ = sequences[0][0]\n",
    "    print(answer_[0])\n",
    "    answer_ = [index_to_word[x] for x in answer_[0] if (x!=0)]\n",
    "    answer_ = ' '.join(answer_)\n",
    "    return answer_\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    zhfont = matplotlib.font_manager.FontProperties(fname='simkai.ttf')\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    attention = [x[::-1] for x in attention]\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 20}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict,fontproperties=zhfont)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict, fontproperties=zhfont)\n",
    "#     ax.yaxis.set_ticks_position('right') #y轴刻度位置靠右\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    seq = input()\n",
    "    if seq == 'x':\n",
    "        break\n",
    "    seq, sentence = input_question(seq)\n",
    "    print(sentence)\n",
    "    answer = decode_greedy(seq, sentence)\n",
    "#     answer=decode_beamsearch(seq, 3)\n",
    "    print('ANSWER: ', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Text, Entry, Button, StringVar, Scrollbar, END\n",
    "from tkinter.messagebox import showinfo\n",
    "import tkinter as tk\n",
    "root = tk.Tk()\n",
    "root.title(\"聊天机器人-小意\")\n",
    "root.geometry(\"425x385\")\n",
    "root.resizable(0,0)\n",
    "root.attributes('-toolwindow', True,\n",
    "                '-alpha', 1,\n",
    "                '-fullscreen', False, \n",
    "                '-topmost', True)\n",
    "showinfo('Hello', '[小意]准备好了！')\n",
    "root.overrideredirect(True)\n",
    "def center_window(w, h):\n",
    "    ws = root.winfo_screenwidth()\n",
    "    hs = root.winfo_screenheight()\n",
    "    x = (ws/2) - (w/2)\n",
    "    y = (hs/2) - (h/2)\n",
    "    root.geometry('%dx%d+%d+%d' % (w, h, x, y))\n",
    "center_window(425, 356)\n",
    "text_recv = Text(root, width=61, height=20, bd=0, selectbackground='#00BFFF')\n",
    "text_recv.place(x=0, y=0)\n",
    "text_recv.tag_config('me_msg', \n",
    "                     foreground='#000000', \n",
    "#                      background='#00BFFF',\n",
    "                     justify='right', \n",
    "                     rmargin=20,\n",
    "                     offset=10,\n",
    "                     borderwidth=10)\n",
    "\n",
    "text_msg = Text(root, width=61, height=6, bd=0)\n",
    "text_msg.place(x=0, y=275)\n",
    "\n",
    "\n",
    "def show():\n",
    "    seq = text_msg.get(\"0.0\", \"end\")\n",
    "    msg_send = seq\n",
    "    print(msg_send)\n",
    "    text_recv.insert(END, msg_send, 'me_msg')\n",
    "    seq, sentence = input_question(seq)\n",
    "    answer = decode_greedy(seq, sentence)\n",
    "    print(answer)\n",
    "    answer = ''.join(answer.split(' ')[:-1])\n",
    "    msg_recv = '[小意]: '+ answer + '\\n'\n",
    "    text_recv.insert(END, msg_recv)\n",
    "    text_msg.delete(\"0.0\", \"end\")\n",
    "Button(root,text='发送信息',width=10,command=show, \n",
    "       bd=0, bg='#00BFFF', fg='#FFFFFF',\n",
    "       activeforeground='#1E90FF').place(x=340,y=330)\n",
    "Button(root,text='quit',width=10,command=root.destroy, \n",
    "       bd=0, bg='#00BFFF', fg='#FFFFFF',\n",
    "       activeforeground='#1E90FF').place(x=20,y=330)\n",
    "Button(root, text=\"清屏\",width=10,command = lambda : text_recv.delete(0.0, END),\n",
    "       bd=0, bg='#00BFFF', fg='#FFFFFF',\n",
    "       activeforeground='#1E90FF').place(x=240,y=330)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
